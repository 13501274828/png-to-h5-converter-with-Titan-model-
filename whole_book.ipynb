{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7f2fb3e-399f-4f5d-abd6-5a59abcabe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zz/Desktop/virtualenvs/pathology_env/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from typing import Union, Dict, List, Tuple, Optional, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, cohen_kappa_score, accuracy_score,\n",
    "    classification_report, log_loss, roc_auc_score\n",
    ")\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "login(\"Your hugging face code\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff19b4be-e48e-4bd9-b0a7-ff3474d477e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zz/Desktop/virtualenvs/pathology_env/lib/python3.13/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n",
      "  0%|                                                   | 0/875 [00:00<?, ?it/s]/Users/zz/Desktop/virtualenvs/pathology_env/lib/python3.13/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
      "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
      "  warnings.warn(error_message)\n",
      "100%|█████████████████████████████████████████| 875/875 [00:21<00:00, 40.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📝 Saved prediction results to: /Users/zz/Desktop/reser/ruiming/pathology/glomerulus/Glom_Patches_nopatches/h5/predictions.csv\n",
      "\n",
      "📊 Zero-Shot Classification Evaluation:\n",
      "/acc: 0.1383\n",
      "/bacc: 0.1421\n",
      "/kappa: -0.0086\n",
      "/nw_kappa: -0.0310\n",
      "/weighted_f1: 0.1160\n",
      "/loss: -1.0000\n",
      "/auroc: -1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = \"/Users/zz/Desktop/reser/ruiming/pathology/glomerulus/Glom_Patches_nopatches/h5/labels.csv\"\n",
    "h5_dir = \"/Users/zz/Desktop/reser/ruiming/pathology/glomerulus/Glom_Patches_nopatches/h5\"\n",
    "yaml_path = \"/Users/zz/Desktop/reser/ruiming/pathology/config_tcga-ot.yaml\"\n",
    "\n",
    "TEMPLATES = [\n",
    "    \"CLASSNAME.\",\n",
    "    \"an image of CLASSNAME.\",\n",
    "    \"the image shows CLASSNAME.\",\n",
    "    \"the image displays CLASSNAME.\",\n",
    "    \"the image exhibits CLASSNAME.\",\n",
    "    \"an example of CLASSNAME.\",\n",
    "    \"CLASSNAME is shown.\",\n",
    "    \"this is CLASSNAME.\",\n",
    "    \"I observe CLASSNAME.\",\n",
    "    \"the pathology image shows CLASSNAME.\",\n",
    "    \"a pathology image shows CLASSNAME.\",\n",
    "    \"the pathology slide shows CLASSNAME.\",\n",
    "    \"shows CLASSNAME.\",\n",
    "    \"contains CLASSNAME.\",\n",
    "    \"presence of CLASSNAME.\",\n",
    "    \"CLASSNAME is present.\",\n",
    "    \"CLASSNAME is observed.\",\n",
    "    \"the pathology image reveals CLASSNAME.\",\n",
    "    \"a microscopic image of showing CLASSNAME.\",\n",
    "    \"histology shows CLASSNAME.\",\n",
    "    \"CLASSNAME can be seen.\",\n",
    "    \"the tissue shows CLASSNAME.\",\n",
    "    \"CLASSNAME is identified.\",\n",
    "]\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"8\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained('MahmoodLab/TITAN', trust_remote_code=True)\n",
    "model = model.to(device)\n",
    "\n",
    "with open(yaml_path, 'r') as file:\n",
    "    task_config = yaml.load(file, Loader=yaml.FullLoader)\n",
    "class_prompts_dict = task_config['prompts']\n",
    "target = task_config['target']\n",
    "label_dict = task_config['label_dict']\n",
    "\n",
    "sorted_class_prompts = dict(sorted(class_prompts_dict.items(), key=lambda item: label_dict.get(item[0], float('inf'))))\n",
    "classes = list(sorted_class_prompts.keys())\n",
    "class_prompts = [sorted_class_prompts[key] for key in sorted_class_prompts.keys()]\n",
    "\n",
    "with torch.autocast(device.type, torch.float16 if device.type == \"cuda\" else torch.float32), torch.inference_mode():\n",
    "    classifier = model.zero_shot_classifier(class_prompts, TEMPLATES, device=device)\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "probs_all = []\n",
    "prediction_records = []\n",
    "\n",
    "for row in tqdm(df.itertuples(), total=len(df)):\n",
    "    h5_path = os.path.join(h5_dir, row.h5_filename)\n",
    "    true_label_str = getattr(row, target)\n",
    "\n",
    "    try:\n",
    "        file = h5py.File(h5_path, 'r')\n",
    "        features = torch.from_numpy(file['features'][:]).to(device)\n",
    "        coords = torch.from_numpy(file['coords'][:]).to(device)\n",
    "        patch_size_lv0 = file['coords'].attrs['patch_size_level0']\n",
    "\n",
    "        with torch.autocast(device.type, torch.float16 if device.type == \"cuda\" else torch.float32), torch.inference_mode():\n",
    "            slide_embedding = model.encode_slide_from_patch_features(features, coords, patch_size_lv0)\n",
    "            scores = model.zero_shot(slide_embedding, classifier)\n",
    "\n",
    "        pred_idx = scores.argmax().item()\n",
    "        pred_label_str = classes[pred_idx]\n",
    "        true_idx = label_dict[true_label_str]\n",
    "\n",
    "        y_true.append(true_idx)\n",
    "        y_pred.append(pred_idx)\n",
    "        probs_all.append(scores.squeeze(0).cpu().numpy())\n",
    "\n",
    "        prediction_records.append({\n",
    "            \"h5_filename\": row.h5_filename,\n",
    "            \"true_label\": true_label_str,\n",
    "            \"pred_label\": pred_label_str,\n",
    "            \"is_correct\": int(pred_label_str == true_label_str)\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" Error with {h5_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "pred_df = pd.DataFrame(prediction_records)\n",
    "pred_df.to_csv(os.path.join(h5_dir, \"predictions.csv\"), index=False)\n",
    "print(f\"\\n Saved prediction results to: {h5_dir}/predictions.csv\")\n",
    "\n",
    "def get_eval_metrics(\n",
    "    targets_all: Union[List[int], np.ndarray],\n",
    "    preds_all: Union[List[int], np.ndarray],\n",
    "    probs_all: Optional[Union[List[float], np.ndarray]] = None,\n",
    "    unique_classes: Optional[List[int]] = None,\n",
    "    get_report: bool = True,\n",
    "    prefix: str = \"\",\n",
    "    roc_kwargs: Dict[str, Any] = {},\n",
    ") -> Dict[str, Any]:\n",
    "    unique_classes = unique_classes if unique_classes is not None else np.unique(targets_all)\n",
    "    bacc = balanced_accuracy_score(targets_all, preds_all) if len(targets_all) > 1 else 0\n",
    "    kappa = cohen_kappa_score(targets_all, preds_all, weights=\"quadratic\")\n",
    "    nw_kappa = cohen_kappa_score(targets_all, preds_all, weights=\"linear\")\n",
    "    acc = accuracy_score(targets_all, preds_all)\n",
    "    cls_rep = classification_report(targets_all, preds_all, output_dict=True, zero_division=0, labels=unique_classes)\n",
    "\n",
    "    eval_metrics = {\n",
    "        f\"{prefix}/acc\": acc,\n",
    "        f\"{prefix}/bacc\": bacc,\n",
    "        f\"{prefix}/kappa\": kappa,\n",
    "        f\"{prefix}/nw_kappa\": nw_kappa,\n",
    "        f\"{prefix}/weighted_f1\": cls_rep[\"weighted avg\"][\"f1-score\"],\n",
    "    }\n",
    "\n",
    "    if probs_all is not None:\n",
    "        if len(np.unique(targets_all)) > 1:\n",
    "            try:\n",
    "                loss = log_loss(targets_all, probs_all, labels=unique_classes)\n",
    "                roc_auc = roc_auc_score(targets_all, probs_all, multi_class='ovo', average=\"macro\", labels=unique_classes)\n",
    "            except ValueError:\n",
    "                roc_auc = -1\n",
    "                loss = -1\n",
    "            eval_metrics[f\"{prefix}/loss\"] = loss\n",
    "            eval_metrics[f\"{prefix}/auroc\"] = roc_auc\n",
    "\n",
    "    return eval_metrics\n",
    "\n",
    "results = get_eval_metrics(y_true, y_pred, probs_all, unique_classes=list(label_dict.values()))\n",
    "print(\"\\n Zero-Shot Classification Evaluation:\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921b5f0-249d-4c29-84f1-cca8c799c56e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathology_env",
   "language": "python",
   "name": "pathology_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
